{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pGEGh2lOXnTJ",
        "outputId": "cf2f5bc7-23fc-4421-a68e-7510d63f9566"
      },
      "outputs": [],
      "source": [
        "# Pake yang ini\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "from fast_ml.model_development import train_valid_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_PATH = r'../../Datasets/train.csv'\n",
        "TEST_PATH = r'../../Datasets/test.csv'\n",
        "SAMPLE_SUBMISSION_PATH = r\"../../Datasets/sample_submission.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dat = pd.read_csv(TRAIN_PATH)\n",
        "test_dat = pd.read_csv(TEST_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26570 entries, 0 to 26569\n",
            "Data columns (total 26 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   id              26570 non-null  int64  \n",
            " 1   product_code    26570 non-null  object \n",
            " 2   loading         26320 non-null  float64\n",
            " 3   attribute_0     26570 non-null  object \n",
            " 4   attribute_1     26570 non-null  object \n",
            " 5   attribute_2     26570 non-null  int64  \n",
            " 6   attribute_3     26570 non-null  int64  \n",
            " 7   measurement_0   26570 non-null  int64  \n",
            " 8   measurement_1   26570 non-null  int64  \n",
            " 9   measurement_2   26570 non-null  int64  \n",
            " 10  measurement_3   26189 non-null  float64\n",
            " 11  measurement_4   26032 non-null  float64\n",
            " 12  measurement_5   25894 non-null  float64\n",
            " 13  measurement_6   25774 non-null  float64\n",
            " 14  measurement_7   25633 non-null  float64\n",
            " 15  measurement_8   25522 non-null  float64\n",
            " 16  measurement_9   25343 non-null  float64\n",
            " 17  measurement_10  25270 non-null  float64\n",
            " 18  measurement_11  25102 non-null  float64\n",
            " 19  measurement_12  24969 non-null  float64\n",
            " 20  measurement_13  24796 non-null  float64\n",
            " 21  measurement_14  24696 non-null  float64\n",
            " 22  measurement_15  24561 non-null  float64\n",
            " 23  measurement_16  24460 non-null  float64\n",
            " 24  measurement_17  24286 non-null  float64\n",
            " 25  failure         26570 non-null  int64  \n",
            "dtypes: float64(16), int64(7), object(3)\n",
            "memory usage: 5.3+ MB\n"
          ]
        }
      ],
      "source": [
        "train_dat.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Prep\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #drop id\n",
        "# train_dat = train_dat.drop(columns='id')\n",
        "# test_dat = test_dat.drop(columns='id')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Null Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26570 entries, 0 to 26569\n",
            "Data columns (total 26 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   id              26570 non-null  int64  \n",
            " 1   product_code    26570 non-null  object \n",
            " 2   loading         26570 non-null  float64\n",
            " 3   attribute_0     26570 non-null  object \n",
            " 4   attribute_1     26570 non-null  object \n",
            " 5   attribute_2     26570 non-null  int64  \n",
            " 6   attribute_3     26570 non-null  int64  \n",
            " 7   measurement_0   26570 non-null  int64  \n",
            " 8   measurement_1   26570 non-null  int64  \n",
            " 9   measurement_2   26570 non-null  int64  \n",
            " 10  measurement_3   26570 non-null  float64\n",
            " 11  measurement_4   26570 non-null  float64\n",
            " 12  measurement_5   26570 non-null  float64\n",
            " 13  measurement_6   26570 non-null  float64\n",
            " 14  measurement_7   26570 non-null  float64\n",
            " 15  measurement_8   26570 non-null  float64\n",
            " 16  measurement_9   26570 non-null  float64\n",
            " 17  measurement_10  26570 non-null  float64\n",
            " 18  measurement_11  26570 non-null  float64\n",
            " 19  measurement_12  26570 non-null  float64\n",
            " 20  measurement_13  26570 non-null  float64\n",
            " 21  measurement_14  26570 non-null  float64\n",
            " 22  measurement_15  26570 non-null  float64\n",
            " 23  measurement_16  26570 non-null  float64\n",
            " 24  measurement_17  26570 non-null  float64\n",
            " 25  failure         26570 non-null  int64  \n",
            "dtypes: float64(16), int64(7), object(3)\n",
            "memory usage: 5.3+ MB\n"
          ]
        }
      ],
      "source": [
        "# drop all null values\n",
        "train_dat = train_dat.fillna(train_dat.mean())\n",
        "test_dat = test_dat.fillna(test_dat.mean())\n",
        "\n",
        "train_dat.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outlier Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [],
      "source": [
        "def handle_outliers_iqr(data):\n",
        "    # Calculate quartiles\n",
        "    Q1 = np.percentile(data, 25)\n",
        "    Q3 = np.percentile(data, 75)\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    # Calculate lower and upper bounds\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    # Handle outliers\n",
        "    # Replace outliers with the upper or lower bound\n",
        "    data[data < lower_bound] = lower_bound\n",
        "    data[data > upper_bound] = upper_bound\n",
        "    \n",
        "    return data\n",
        "\n",
        "for column in train_dat.select_dtypes(include=np.number):\n",
        "    if column != 'failure':\n",
        "        train_dat[column] = handle_outliers_iqr(train_dat[column])\n",
        "        test_dat[column] = handle_outliers_iqr(test_dat[column])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### One hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Perform one-hot encoding\n",
        "# train_dat = pd.get_dummies(train_dat, columns=['attribute_0', 'attribute_1'])\n",
        "# test_dat = pd.get_dummies(test_dat, columns=['attribute_0', 'attribute_1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [],
      "source": [
        "def label_encoder(train, test, columns):\n",
        "    for col in columns:\n",
        "        train[col] = train[col].astype(str)\n",
        "        test[col] = test[col].astype(str)\n",
        "        train[col] = LabelEncoder().fit_transform(train[col])\n",
        "        test[col] = LabelEncoder().fit_transform(test[col])\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_features = ['product_code','attribute_0', 'attribute_1' ]\n",
        "train_dat, test_dat = label_encoder(train_dat, test_dat, cat_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dari notebook explore.ipynb\n",
        "\n",
        "train_dat = train_dat[['loading', 'measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'failure']]\n",
        "test_dat = test_dat[['loading', 'measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SPLIT TRAIN AND TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Memisahkan fitur dengan target\n",
        "full_train = train_dat.drop(columns=[\"failure\"])\n",
        "full_target = train_dat[\"failure\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "mSRiKNXrb47c"
      },
      "outputs": [],
      "source": [
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                        full_train,\n",
        "                                        full_target,\n",
        "                                        test_size=0.3,\n",
        "                                        random_state=42,\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE for oversampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FEATURE SCALING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "6ozDzrB8bh0e"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ozhFADaeMUr",
        "outputId": "7717c149-903b-4b60-915b-b938f2522695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(29198, 12)\n",
            "(7971, 12)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [],
      "source": [
        "def metrics(y_true, y_pred):\n",
        "    print(\"ROC_AUC  :\", roc_auc_score(y_true, y_pred))\n",
        "\n",
        "def train_eval_models(models: dict, X_train, X_test, y_train, y_test):\n",
        "    for model in models:\n",
        "        m = model\n",
        "        m.fit(X_train, y_train)\n",
        "        y_pred = m.predict(X_test)\n",
        "        print(model.__class__.__name__, models[model])\n",
        "        metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuning KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Load the dataset\n",
        "\n",
        "# # Define parameter grid\n",
        "# param_grid = {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance']}\n",
        "\n",
        "# # Choose a cross-validation strategy\n",
        "# cv = 5  # 5-fold cross-validation\n",
        "\n",
        "# # Choose a performance metric\n",
        "# scoring = 'roc_auc'\n",
        "\n",
        "# # Initialize KNN classifier\n",
        "# knn = KNeighborsClassifier()\n",
        "\n",
        "# # Perform grid search\n",
        "# grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=cv, scoring=scoring)\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Get the best hyperparameters\n",
        "# best_params = grid_search.best_params_\n",
        "# best_score = grid_search.best_score_\n",
        "\n",
        "# print(\"Best Hyperparameters:\", best_params)\n",
        "# print(\"Best Score:\", best_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [],
      "source": [
        "# svm_model = SVC()\n",
        "# svm_model.fit(X_train, y_train)\n",
        "\n",
        "# y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC_AUC  : 0.5114617987683043\n"
          ]
        }
      ],
      "source": [
        "# Best hyperparameters obtained from hyperparameter tuning\n",
        "best_params = {'n_neighbors': 5, 'weights': 'distance'}  # Example values\n",
        "# n_neighbors=best_params['n_neighbors'], weights=best_params['weights']\n",
        "# Instantiate the KNN classifier with the best hyperparameters\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn_model.predict(X_test)\n",
        "\n",
        "metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC_AUC  : 0.5413562023823936\n"
          ]
        }
      ],
      "source": [
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kaggle Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [],
      "source": [
        "submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
        "submission['failure'] = nb_model.predict(test_dat)\n",
        "submission.to_csv('../submissions/testing_3.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = pd.read_csv('../submissions/submission_1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     9129\n",
            "1    11646\n",
            "Name: failure, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "count_promosi = file['failure'].value_counts().sort_index()\n",
        "print(count_promosi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iFPNmVB20MRF"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
